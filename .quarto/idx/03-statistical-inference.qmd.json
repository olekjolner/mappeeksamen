{"title":"Assignment 3: Drawing inference from statistical models, and statistical power","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"}},"headingText":"Assignment 3: Drawing inference from statistical models, and statistical power","containsRefs":false,"markdown":"\n\n\n## Introduksjon\nStatistisk inferens er en type statistikk som omhandler metoder for å trekke konklusjoner om en populasjon basert på et utvalg. Målet er å generalisere funnene fra utvalget og bruke det til å si noe om hele populasjonen. En viktig del av statistisk inferens er å vurdere usikkerheten i estimatene, typisk ved hjelp av konfidensintervaller og p-verdier [@Cremers].\n\nEffektstørrelser gir en kvantitativ vurdering av hvor betydelig en observert effekt er, og er ikke avhengig av utvalgsstørrelse. Dette er nyttig i forskning, da det hjelper med å forstå de praktiske betydningene av funnene man har gjort. Ved å kombinere statistisk inferens med effektstørrelser kan man bedre vurdere resultatene sine og sette det i en bred kontekst [@Cremers]. \n\n\n\n```{r}\n#| code-fold: true\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(gt)\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\n#lager to ulike utvalg der gruppe 1 er n=8 og gruppe 2 n=40\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\nsum1 <- summary(m1) \nsum2 <- summary(m2)\n```\n\n```{r, fig.width=6, fig.height=4}\n#| code-fold: true\n#| warning: false\n#| message: false\n\n\n# plotter samp 1 og 2 for å illustrere den relative spredningen i utvalget\nsamp1 |> \n  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = \"orange\") +\n  geom_vline(xintercept = coef(sum1)[1], color = \"steelblue\", linewidth = 1.5) +\n  annotate(\"richtext\", \n           x = coef(sum1)[1], \n           y = 0.99, \n           label = \"estimate\", \n           angle = -90) +\n  coord_cartesian(y = c(0.98, 1.02)) +\n  labs(subtitle = \"Illustrasjon av spredning i verdier\", \n       caption = \"Utvalg 1 fra populasjonen (n = 8)\",\n       x = \"\", \n       y = \"\")\n\nsamp2 |> \n  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = \"red\") + \n  geom_vline(xintercept = coef(sum2)[1], color = \"steelblue\", linewidth = 1.5) +\n  annotate(\"richtext\", \n           x = coef(sum2)[1], \n           y = 0.99, \n           label = \"estimate\", \n           angle = -90) +\n  coord_cartesian(y = c(0.98, 1.02)) +\n  labs(subtitle = \"Illustrasjon av spredning i verdier\",\n       caption = \"Utvalg 2 fra populasjonen (n = 40)\", \n       x = \"\", \n       y = \"\")\n  \n```\n\n## Forklar estimatet, standard error (SE), *t*-verdien, *p*-verdien fra regresjonen som vi lagde fra m1 og m2\n\n### <u>*t*-verdi</u>\n\nT-verdien brukes for å sammenlikne gjennomsnittet av to ulike datasett.\nT-verdien tar altså differansen mellom gjennomsnittet av\nutvalget og gjennomsnittet av populasjonen, og ser på det i forhold til\nstandardavviket over kvadratroten av antallet i utvalget, slik som\nformelen viser under.\n\n$t = \\frac{(\\overline{x}-\\mu_{0})} {\\frac{s} {\\sqrt n}}$, der $\\overline{x}$ = gjennomsnittet av utvalget, $\\mu_{0}$ = gjennomsnittet\nav populajsonen, s = standardavviket, n = størrelsen av utvalget\n\nT-verdien brukes for å støtte opp under vår nullhypotese, eller forkaste\nden. Jo nærmere *t* er null, destod større sannsynlighet for at det ikke\ner noen signifikant forskjell. Hvis vi tar høyde for at gruppen med\nstørst utvalg vil være den gruppen med minst feilmargin, vil dette\nstemme i vårt tilfelle med sample 1 og 2, der t er større i sample 1\n(`r round(coef(sum1)[3], digits = 3)`), sammenliknet med t i sample 2\n(`r round(coef(sum2)[3], digits = 3)`).\n\n### <u>*p*-verdi</u>\n\nSier noe om usikkerheten i trekningen av utvalget. Kanskje trakk man i\nsample 1 bare ekstreme verdier. Utvalget vil neppe bli en perfekt\nrepresentasjon av populasjonen uansett hvordan man trekker ett utvalg.\nDette er en usikkerhet man må ta høyde for i ulike studier og dette kan\np-verdien hjelpe oss å si noe om. Om vi tar høyde for at nullhypotesten\nstemmer, hvor mange verdier kan vi forvente er mer ekstreme enn våre\nobservasjoner. *p*-veriden måler altså observasjonene våre opp mot den\nspesifikke nullhypotesen.\n\n### <u>SE</u>\n\nstandard error er en måte å angi feilmarginen av et estimat eller\nmåling. Man benytter ofte sentralgrenseteoremet i denne sammenhengen,\nsom sier at hvis man gjør en undersøkelse mange ganger, vil resulatene\nsamle seg omkring den sanne verdien. Jo større utvalg, jo mindre\nfeilmargin.\\\nManuelt kan man beregne SE ved å ta standardavviket og dele på\nkvadratroten av antall observasjoner. Dette gir oss altså et svar på\nhvor langt unna det sanne gjennomsnittet kan vi forvente å komme. I\ntilfellet vårt ser vi at SE for sample 1 er tydelig større enn i sample\n2, nettopp pga et mindre utvalg i sample 1. Vi kan altså forvente å få\nverdier lenger unna den sanne gjennomsnittsverdien ved et mindre utvalg.\n\n### <u>Estimatet</u>\n\nEstmatet er gjennomsnittet av alle verdiene i utvalget, så i sample 1 er\nestmiatet `r round(coef(sum1)[1], digits = 3)` og i sample 2 er\nestimatet `r round(coef(sum2)[1], digits = 3)`.\n\n## Hva bidrar til de ulike resulatene i de to studiene (m1 og m2)\n\nForskjellen mellom sample 1 og 2 er antall som trekkes ut, utvalget. Med\net større utvalg blir SE lavere og *p*-verdien også lavere, sammenlinket\nmed et utvalg som er mindre.\n\n## Hvorfor benytter vi begge \"halene\" i t-fordelingen (two-tailed test)\n\nEn two-tailed test tillater at man ser på mulighet for endring i begge\nretninger, altså positiv og negativ retning. Hvis man undersøker ulike\nbehandlinger, for eksempel for blodtrykk, vil man være interessert i å se på\npositive og negative endringer mellom grupper. \n\n```{r}\n#| code-fold: true\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n```\n\n## Kalkuler standardavvik for estimat-variabelen og gjennomsnittet av se-variabelen for begge utvalgene.\n\nStandard error: $SE = \\frac{\\sigma}{\\sqrt n}$ , der $\\sigma$ =\nstandardavviket for utvalget og n = antall i utvalget.\n\n```{r}\n#| code-fold: true\n\nsd_est_8 <- sd(results_8$estimate) \nmean_se_8 <- mean(results_8$se)\n\nsd_est_40 <- sd(results_40$estimate)\nmean_se_40 <- mean(results_40$se)\n\n```\n\nFor utvalget med n=8 er standardavviket for snittet av utvalget\n`r round(sd_est_8, digits = 3)` og gjennomsnittet av standardfeilen\n`r round(mean_se_8, digits = 3)`. Altså tilnærmet likt. Det samme\ngjelder for utvalget med n=40 (bare med mindre avvik) der\nstandardavviket for snittet av utvalget er\n`r round(sd_est_40, digits = 3)` og gjennomsnittet av standardfeilen er\n`r round(mean_se_40, digits = 3)`. \nHvordan kan man definere standardfeilen, sett i lys av disse variablene?\nPå generell basis kan man si at SE for et utvalg er et estimat på standardavviket til den teoretiske fordelingen av gjennomsnitt. Observerer at når \"n\" (utvalget) øker, vil standardfeilen synke (ref. formel for beregning av SE). \n\n## Lag et histogram av *p*-verdiene for de to uvalgene. Hvordan kan histogrammene tolkes og hva forteller de om effekten av størrelsen av utvalget for statistisk styrke?\n\n```{r}\n#| code-fold: true\n\nlibrary(ggtext)\nlibrary(dplyr)\nlibrary(gt)\n\n# A two facets histogram can be created with ggplot2\nresults %>%\n  ggplot(aes(pval)) + \n  geom_histogram(bins = 25, \n                 color = \"black\", \n                 fill = \"orange\") +\n  facet_wrap(~ n) + \n  labs(x = \"*p*-values\", \n       y = \"Number of simulations\", \n       subtitle = \"Fordelingen av *p*-verdier fra 1000 simuleringer\", \n       caption = \"Hver bar representerer antall simuleringer av en gitt *p*-verdi\") +\n  theme(axis.title.x = element_markdown()) +\ntheme(plot.subtitle = element_markdown()) +\n  theme(plot.caption = element_markdown())\n\n\n# Count the proportion of tests below a certain p-value for each \nresults %>%\n  filter(pval < 0.05) %>%\n  group_by(n) %>%\n  summarise(sig_results = n()/1000) |> \n  gt() |> \n  tab_caption(\"Summering av signifikante resultater\") |> \n  cols_label(n = \"Utvalgsstr.\", \n             sig_results = \"Signif. res. / 1000\")\n```\nI histogrammet med n=8 kan er se stor variasjon innad i utvalgene. Ved de 1000 simuleringene som er gjort er det sannsynlig at det har vært stor spredning i de variablene som er trekt i samme utvalg (og motsatt). Dermed vil disse enkelt-utvalgene gjøre utslag på *p*-verdien begge veier. Ved å plotte det slik fremheves også tendensen til falsk-positive simuleringer ved p = 0.05. En falsk positiv oppstår når en test indikerer en signifikant effekt, slik at man forkaster nullhypotesten (H~0~), men det egentlig ikke er en effekt der (H~0~ er sann). \n\n\n## Antall observasjoner fra hvert utvalg som er under signifikansnivået på 0.05\n\n```{r}\n#| code-fold: true\n\nn_sig_8 <- results |> \n  filter(pval < 0.05) |> \n  filter(n != 40) |> \n  nrow()\nn_sig_40 <- results |> \n  filter(pval < 0.05) |> \n  filter(n == 40) |> \n  nrow()\n\n```\n\n\nSetter signifikansnivå til p \\< 0.05 Det er `r n_sig_40` tilfeller der p\n\\< 0.05 for utvalget med 40. Det er `r n_sig_8` tilfeller der p\\< 0.05\nfor utvalget med 8.\n\n\n## Estmerer effekten ved one-sample t-test\n```{r}\n#| code-fold: true\n\n# Using the pwr package\nlibrary(pwr)\n\npwr_8 <- pwr.t.test(n = 8, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\npwr_40 <- pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\n\npwr_8\npwr_40\n```\n\nEffekt ved utavlget på 8 stk: `r round(pwr_8$power, digits = 3)`. Effekt\nved utvalget på 40 stk: `r round(pwr_40$power, digits = 3)`.\nEn kan forvente høyere effekt med et større utvalg. Dette observeres i vårt tilfelle. Med høyere effekt, vil en også forvente å se større grad av signifikans, altså en lavere *p*-verdi (som også er tilfellet i denne simuleringen). \n\n\n\n## Ved å benytte det nye datasettet: hvor mange tilfeller av \"falsk positive\"-tester vil vi komme over ved å repetere studien mange ganger?\n\n```{r}\n#| code-fold: true\n\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n}\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n```\n\n\n```{r, fig.width=6, fig.height=4}\n#| code-fold: true\n\n#lager histogram for koden over\n\nggplot(data = results_null, aes(pval)) +\n  geom_histogram(binwidth = 0.05, \n                 color = \"black\", fill = \"lightgreen\",) +\nfacet_wrap(~ n) +\n  labs(subtitle = \"Fordelingen av *p*-verdier fra 1000 simuleringer\", \n       caption = \"Hver bar representerer antall simuleringer av en gitt *p*-verdi\", \n       x = \"*p*-verdier\", \n       y = \"Number of simulations\") +\n  theme(axis.title.x = element_markdown()) +\ntheme(plot.subtitle = element_markdown()) +\n  theme(plot.caption = element_markdown())\n\n\n```\n\n\n```{r}\n#| code-fold: true\n\nfalsepos_8 <- results_null |> \n  filter(results_null$pval < 0.05, n == 8) |> \n  nrow()\n  \nfalsepos_40 <- results_null |> \n  filter(results_null$pval < 0.05, n == 40) |> \n  nrow()\n\n```\n\n\nVed å repetere studien 1000 ganger, vil vi komme over `r falsepos_8`\nfalsk-positive tester for utvalget med 8, og `r falsepos_40` for\nutvalget med 40. Totalt antall falsk-positive tester blir\n`r (falsepos_8 + falsepos_40)`.\n\n## Referanser\n\n","srcMarkdownNoYaml":"\n\n# Assignment 3: Drawing inference from statistical models, and statistical power\n\n## Introduksjon\nStatistisk inferens er en type statistikk som omhandler metoder for å trekke konklusjoner om en populasjon basert på et utvalg. Målet er å generalisere funnene fra utvalget og bruke det til å si noe om hele populasjonen. En viktig del av statistisk inferens er å vurdere usikkerheten i estimatene, typisk ved hjelp av konfidensintervaller og p-verdier [@Cremers].\n\nEffektstørrelser gir en kvantitativ vurdering av hvor betydelig en observert effekt er, og er ikke avhengig av utvalgsstørrelse. Dette er nyttig i forskning, da det hjelper med å forstå de praktiske betydningene av funnene man har gjort. Ved å kombinere statistisk inferens med effektstørrelser kan man bedre vurdere resultatene sine og sette det i en bred kontekst [@Cremers]. \n\n\n\n```{r}\n#| code-fold: true\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(gt)\n\nset.seed(1)\npopulation <- rnorm(1000000, mean = 1.5, sd = 3)\n\n#lager to ulike utvalg der gruppe 1 er n=8 og gruppe 2 n=40\nsamp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n\nsamp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n\nm1 <- lm(y ~ 1, data = samp1)\nm2 <- lm(y ~ 1, data = samp2)\n\nsum1 <- summary(m1) \nsum2 <- summary(m2)\n```\n\n```{r, fig.width=6, fig.height=4}\n#| code-fold: true\n#| warning: false\n#| message: false\n\n\n# plotter samp 1 og 2 for å illustrere den relative spredningen i utvalget\nsamp1 |> \n  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = \"orange\") +\n  geom_vline(xintercept = coef(sum1)[1], color = \"steelblue\", linewidth = 1.5) +\n  annotate(\"richtext\", \n           x = coef(sum1)[1], \n           y = 0.99, \n           label = \"estimate\", \n           angle = -90) +\n  coord_cartesian(y = c(0.98, 1.02)) +\n  labs(subtitle = \"Illustrasjon av spredning i verdier\", \n       caption = \"Utvalg 1 fra populasjonen (n = 8)\",\n       x = \"\", \n       y = \"\")\n\nsamp2 |> \n  ggplot(aes(y, 1)) + geom_point(size = 3, shape = 21, fill = \"red\") + \n  geom_vline(xintercept = coef(sum2)[1], color = \"steelblue\", linewidth = 1.5) +\n  annotate(\"richtext\", \n           x = coef(sum2)[1], \n           y = 0.99, \n           label = \"estimate\", \n           angle = -90) +\n  coord_cartesian(y = c(0.98, 1.02)) +\n  labs(subtitle = \"Illustrasjon av spredning i verdier\",\n       caption = \"Utvalg 2 fra populasjonen (n = 40)\", \n       x = \"\", \n       y = \"\")\n  \n```\n\n## Forklar estimatet, standard error (SE), *t*-verdien, *p*-verdien fra regresjonen som vi lagde fra m1 og m2\n\n### <u>*t*-verdi</u>\n\nT-verdien brukes for å sammenlikne gjennomsnittet av to ulike datasett.\nT-verdien tar altså differansen mellom gjennomsnittet av\nutvalget og gjennomsnittet av populasjonen, og ser på det i forhold til\nstandardavviket over kvadratroten av antallet i utvalget, slik som\nformelen viser under.\n\n$t = \\frac{(\\overline{x}-\\mu_{0})} {\\frac{s} {\\sqrt n}}$, der $\\overline{x}$ = gjennomsnittet av utvalget, $\\mu_{0}$ = gjennomsnittet\nav populajsonen, s = standardavviket, n = størrelsen av utvalget\n\nT-verdien brukes for å støtte opp under vår nullhypotese, eller forkaste\nden. Jo nærmere *t* er null, destod større sannsynlighet for at det ikke\ner noen signifikant forskjell. Hvis vi tar høyde for at gruppen med\nstørst utvalg vil være den gruppen med minst feilmargin, vil dette\nstemme i vårt tilfelle med sample 1 og 2, der t er større i sample 1\n(`r round(coef(sum1)[3], digits = 3)`), sammenliknet med t i sample 2\n(`r round(coef(sum2)[3], digits = 3)`).\n\n### <u>*p*-verdi</u>\n\nSier noe om usikkerheten i trekningen av utvalget. Kanskje trakk man i\nsample 1 bare ekstreme verdier. Utvalget vil neppe bli en perfekt\nrepresentasjon av populasjonen uansett hvordan man trekker ett utvalg.\nDette er en usikkerhet man må ta høyde for i ulike studier og dette kan\np-verdien hjelpe oss å si noe om. Om vi tar høyde for at nullhypotesten\nstemmer, hvor mange verdier kan vi forvente er mer ekstreme enn våre\nobservasjoner. *p*-veriden måler altså observasjonene våre opp mot den\nspesifikke nullhypotesen.\n\n### <u>SE</u>\n\nstandard error er en måte å angi feilmarginen av et estimat eller\nmåling. Man benytter ofte sentralgrenseteoremet i denne sammenhengen,\nsom sier at hvis man gjør en undersøkelse mange ganger, vil resulatene\nsamle seg omkring den sanne verdien. Jo større utvalg, jo mindre\nfeilmargin.\\\nManuelt kan man beregne SE ved å ta standardavviket og dele på\nkvadratroten av antall observasjoner. Dette gir oss altså et svar på\nhvor langt unna det sanne gjennomsnittet kan vi forvente å komme. I\ntilfellet vårt ser vi at SE for sample 1 er tydelig større enn i sample\n2, nettopp pga et mindre utvalg i sample 1. Vi kan altså forvente å få\nverdier lenger unna den sanne gjennomsnittsverdien ved et mindre utvalg.\n\n### <u>Estimatet</u>\n\nEstmatet er gjennomsnittet av alle verdiene i utvalget, så i sample 1 er\nestmiatet `r round(coef(sum1)[1], digits = 3)` og i sample 2 er\nestimatet `r round(coef(sum2)[1], digits = 3)`.\n\n## Hva bidrar til de ulike resulatene i de to studiene (m1 og m2)\n\nForskjellen mellom sample 1 og 2 er antall som trekkes ut, utvalget. Med\net større utvalg blir SE lavere og *p*-verdien også lavere, sammenlinket\nmed et utvalg som er mindre.\n\n## Hvorfor benytter vi begge \"halene\" i t-fordelingen (two-tailed test)\n\nEn two-tailed test tillater at man ser på mulighet for endring i begge\nretninger, altså positiv og negativ retning. Hvis man undersøker ulike\nbehandlinger, for eksempel for blodtrykk, vil man være interessert i å se på\npositive og negative endringer mellom grupper. \n\n```{r}\n#| code-fold: true\n\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults <- bind_rows(results_8, results_40)\n```\n\n## Kalkuler standardavvik for estimat-variabelen og gjennomsnittet av se-variabelen for begge utvalgene.\n\nStandard error: $SE = \\frac{\\sigma}{\\sqrt n}$ , der $\\sigma$ =\nstandardavviket for utvalget og n = antall i utvalget.\n\n```{r}\n#| code-fold: true\n\nsd_est_8 <- sd(results_8$estimate) \nmean_se_8 <- mean(results_8$se)\n\nsd_est_40 <- sd(results_40$estimate)\nmean_se_40 <- mean(results_40$se)\n\n```\n\nFor utvalget med n=8 er standardavviket for snittet av utvalget\n`r round(sd_est_8, digits = 3)` og gjennomsnittet av standardfeilen\n`r round(mean_se_8, digits = 3)`. Altså tilnærmet likt. Det samme\ngjelder for utvalget med n=40 (bare med mindre avvik) der\nstandardavviket for snittet av utvalget er\n`r round(sd_est_40, digits = 3)` og gjennomsnittet av standardfeilen er\n`r round(mean_se_40, digits = 3)`. \nHvordan kan man definere standardfeilen, sett i lys av disse variablene?\nPå generell basis kan man si at SE for et utvalg er et estimat på standardavviket til den teoretiske fordelingen av gjennomsnitt. Observerer at når \"n\" (utvalget) øker, vil standardfeilen synke (ref. formel for beregning av SE). \n\n## Lag et histogram av *p*-verdiene for de to uvalgene. Hvordan kan histogrammene tolkes og hva forteller de om effekten av størrelsen av utvalget for statistisk styrke?\n\n```{r}\n#| code-fold: true\n\nlibrary(ggtext)\nlibrary(dplyr)\nlibrary(gt)\n\n# A two facets histogram can be created with ggplot2\nresults %>%\n  ggplot(aes(pval)) + \n  geom_histogram(bins = 25, \n                 color = \"black\", \n                 fill = \"orange\") +\n  facet_wrap(~ n) + \n  labs(x = \"*p*-values\", \n       y = \"Number of simulations\", \n       subtitle = \"Fordelingen av *p*-verdier fra 1000 simuleringer\", \n       caption = \"Hver bar representerer antall simuleringer av en gitt *p*-verdi\") +\n  theme(axis.title.x = element_markdown()) +\ntheme(plot.subtitle = element_markdown()) +\n  theme(plot.caption = element_markdown())\n\n\n# Count the proportion of tests below a certain p-value for each \nresults %>%\n  filter(pval < 0.05) %>%\n  group_by(n) %>%\n  summarise(sig_results = n()/1000) |> \n  gt() |> \n  tab_caption(\"Summering av signifikante resultater\") |> \n  cols_label(n = \"Utvalgsstr.\", \n             sig_results = \"Signif. res. / 1000\")\n```\nI histogrammet med n=8 kan er se stor variasjon innad i utvalgene. Ved de 1000 simuleringene som er gjort er det sannsynlig at det har vært stor spredning i de variablene som er trekt i samme utvalg (og motsatt). Dermed vil disse enkelt-utvalgene gjøre utslag på *p*-verdien begge veier. Ved å plotte det slik fremheves også tendensen til falsk-positive simuleringer ved p = 0.05. En falsk positiv oppstår når en test indikerer en signifikant effekt, slik at man forkaster nullhypotesten (H~0~), men det egentlig ikke er en effekt der (H~0~ er sann). \n\n\n## Antall observasjoner fra hvert utvalg som er under signifikansnivået på 0.05\n\n```{r}\n#| code-fold: true\n\nn_sig_8 <- results |> \n  filter(pval < 0.05) |> \n  filter(n != 40) |> \n  nrow()\nn_sig_40 <- results |> \n  filter(pval < 0.05) |> \n  filter(n == 40) |> \n  nrow()\n\n```\n\n\nSetter signifikansnivå til p \\< 0.05 Det er `r n_sig_40` tilfeller der p\n\\< 0.05 for utvalget med 40. Det er `r n_sig_8` tilfeller der p\\< 0.05\nfor utvalget med 8.\n\n\n## Estmerer effekten ved one-sample t-test\n```{r}\n#| code-fold: true\n\n# Using the pwr package\nlibrary(pwr)\n\npwr_8 <- pwr.t.test(n = 8, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\npwr_40 <- pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\n\npwr_8\npwr_40\n```\n\nEffekt ved utavlget på 8 stk: `r round(pwr_8$power, digits = 3)`. Effekt\nved utvalget på 40 stk: `r round(pwr_40$power, digits = 3)`.\nEn kan forvente høyere effekt med et større utvalg. Dette observeres i vårt tilfelle. Med høyere effekt, vil en også forvente å se større grad av signifikans, altså en lavere *p*-verdi (som også er tilfellet i denne simuleringen). \n\n\n\n## Ved å benytte det nye datasettet: hvor mange tilfeller av \"falsk positive\"-tester vil vi komme over ved å repetere studien mange ganger?\n\n```{r}\n#| code-fold: true\n\npopulation <- rnorm(1000000, mean = 0, sd = 3)\n\n# Create data frames to store the model estimates\nresults_8 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 <- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 <- lm(y ~ 1, data = samp1)\n  m2 <- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] <- coef(summary(m1))[1, 1]\n  results_8[i, 2] <- coef(summary(m1))[1, 2]\n  results_8[i, 3] <- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] <- coef(summary(m2))[1, 1]\n  results_40[i, 2] <- coef(summary(m2))[1, 2]\n  results_40[i, 3] <- coef(summary(m2))[1, 4]\n  \n}\n\n# Save the results in a combined data frame\n\nresults_null <- bind_rows(results_8, results_40)\n```\n\n\n```{r, fig.width=6, fig.height=4}\n#| code-fold: true\n\n#lager histogram for koden over\n\nggplot(data = results_null, aes(pval)) +\n  geom_histogram(binwidth = 0.05, \n                 color = \"black\", fill = \"lightgreen\",) +\nfacet_wrap(~ n) +\n  labs(subtitle = \"Fordelingen av *p*-verdier fra 1000 simuleringer\", \n       caption = \"Hver bar representerer antall simuleringer av en gitt *p*-verdi\", \n       x = \"*p*-verdier\", \n       y = \"Number of simulations\") +\n  theme(axis.title.x = element_markdown()) +\ntheme(plot.subtitle = element_markdown()) +\n  theme(plot.caption = element_markdown())\n\n\n```\n\n\n```{r}\n#| code-fold: true\n\nfalsepos_8 <- results_null |> \n  filter(results_null$pval < 0.05, n == 8) |> \n  nrow()\n  \nfalsepos_40 <- results_null |> \n  filter(results_null$pval < 0.05, n == 40) |> \n  nrow()\n\n```\n\n\nVed å repetere studien 1000 ganger, vil vi komme over `r falsepos_8`\nfalsk-positive tester for utvalget med 8, og `r falsepos_40` for\nutvalget med 40. Totalt antall falsk-positive tester blir\n`r (falsepos_8 + falsepos_40)`.\n\n## Referanser\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"03-statistical-inference.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","bibliography":["bibliography.bib"],"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}